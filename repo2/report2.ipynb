{"metadata":{"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"def sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\ndef softmax(x):\n    x_exp = np.exp(x)\n    return x_exp / np.sum(x_exp)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n\ndef init_network():\n    network = {}\n    network['W1'] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n    network['b1'] = np.array([[0.1, 0.2, 0.3]])\n    network['W2'] = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n    network['b2'] = np.array([[0.1, 0.2]])\n    network['W3'] = np.array([[0.1, 0.3], [0.2, 0.4]])\n    network['b3'] = np.array([[0.1, 0.2]])\n    return network\n\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\ndef forward(network, x):\n    # layer1\n    W1 = network['W1']\n    b1 = network['b1']\n    a1 = np.dot(x, W1) + b1\n    z1 = sigmoid(a1)\n    # layer2\n    W2 = network['W2']\n    b2 = network['b2']\n    a2 = np.dot(z1, W2) + b2\n    z2 = sigmoid(a2)\n    # layer3\n    W3 = network['W3']\n    b3 = network['b3']\n    a3 = np.dot(z2, W3) + b3\n    return a3\n\n\n    network = init_network()\n    x = np.array([1.0, 0.5])\n    y = forward(network, x)\n    print(y)#[0.31682708 0.69627909]","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport random  \nnetwork = init_network()\nbatch_size = 16\nx=np.random.rand(1000,2)\nfor i in range(0,len(x),batch_size):\n    x_batch = x[i:i+batch_size]\n    y_batch = forward(network,x_batch)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"感想\nNNの実装において、1度は[0.31682708 0.69627909]という値が出たのだが、その後データが消えてしまい、再びNNの実装を行っても[0.31682708 0.69627909]が出なかったのが不思議だった。\nnumpyの機能についてよく知る必要があると感じた。\nニュートラルネットワークについては自分でも1から作れるようにしっかり理解しておきたい。\nバッチ処理は処理時間が短縮できることが分かった。\n\n参考文献 『ゼロから作るDeep Learning』","metadata":{},"execution_count":null,"outputs":[]}]}